<!DOCTYPE html>
<html>

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>
        SVS
    </title>

    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="stylesheet" href="../css/main.css">
    <link rel="canonical" href="/">

</head>

<body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>
        <!-- Nav Bar -->
        <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
            <div class="container">
                <!-- Logo -->
                <a href="index.html" class="navbar-brand">
                    <!-- <img src="images/logo.png" alt="Logo" style="height: 60px;">  -->
                </a>
                <!-- Navbar Toggle -->
                <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar top-bar"></span>
                    <span class="icon-bar middle-bar"></span>
                    <span class="icon-bar bottom-bar"></span>
                </button>
                <div class="collapse navbar-collapse text-right" id="navbarNav">
                    <ul class="navbar-nav ml-auto flex-nowrap">
                        <!-- About -->
                        <li class="nav-item active">
                            <a class="nav-link" href="../index.html">
                                Home              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="research.html">
                                Research              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="education.html">
                                Education              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="work.html">
                                Work             
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="others.html">
                                Others              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="../svs-cv.pdf">
                                Resume              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                    </ul>
                </div>
            </div>
        </nav>

    </header>


    <!-- Content -->

    <!-- Content -->

    <div class="container mt-5">
        <div class="post">

            <header class="post-header">
                <h1 class="post-title-research-page">
                    <span class="font-weight-bold"><span style="color: red;">Research</span></span>
                </h1>
                <p class="desc"></p>
            </header>

            <article>

                <div class="clearfix">
                    <p>
                        My research interests span from development of new machine learning and deep learning models to applications of the models to a diverse set of applications in science and engineering. I've previously worked on:
                    </p>
                    <p>
                        1. Development and applications of equivariant neural networks for various applications.
                    </p>
                    <p>
                        2. Development and applications of ML models for healthcare applications, primarily cardiovascular field.
                    </p>
                    <p>
                        3. Development and applications of RAGs, GANs, and NLP systems.
                    </p>
                    <hr>

                </div>

            </article>

            <article>

                <header class="post-header">
                    <h1 class="post-title-research-page">
                        <span class="font-weight-bold">Research Experience</span>
                    </h1>
                    <p class="desc"></p>
                </header>

                <div class="clearfix">
                    <h5><strong>CarDS Lab, Yale University</strong></h5>
                    <p><strong>Data Scientist</strong>, New Haven, CT</p>
                    <p>May 2023 - Present</p>
                    <p>As a Data Scientist at the Cardiovascular Data Science Lab, Yale University, I leverage machine learning and natural language processing to advance cardiovascular data science research. My work encompasses diverse research projects, including Generative Adversarial Networks (GANs) for synthetic data generation, Retrieval-Augmented Generation (RAG) methods, and machine learning models for ECG image analysis. In addition to research, I build robust data infrastructures, including data architecture, mobile applications, and websites, to recruit research participants and deploy models on publicly accessible platforms.</p>
                    <p><strong>PI: </strong><a href="https://medicine.yale.edu/profile/rohan-khera/" target="_blank">Dr. Rohan Khera</a></p>
                    <hr>
                    <h5><strong>Geometric Learning Lab, Northeastern University</strong></h5>
                    <p><strong>Research Fellow</strong>, Boston, MA</p>
                    <p>Aug 2022 - Sep 2023</p>
                    <p>As a part of the Khoury Research Apprenticeship Program in Fall 2022 and Spring 2023, I focused on applying Geometric Deep Learning and Equivariant Neural Networks to fluid mechanics and material sciences. My research involved analyzing the symmetries inherent in fluid dynamics and optics, and developing scale, translation, and rotation symmetric equivariant neural networks that integrates physical priors, enhancing physical realism and data efficiency.</p>
                    <p><strong>PI: </strong><a href="https://www.robinwalters.com/" target="_blank">Dr. Robin Walters</a></p>
                    <hr>
                    <h5><strong>Cybersecurity and Privacy Institute, Northeastern University</strong></h5>
                    <p><strong>Research Assistant</strong>, Boston, MA</p>
                    <p>Jan 2022 - Dec 2022</p>
                    <p>Designed, collected, and analyzed Internet measurement campaigns to illuminate data localization practices in the European Union. Also implemented proof-of-concept models for various research papers and developed machine learning models to predict the physical locations of IP addresses.</p>
                    <p><strong>PI: </strong><a href="https://david.choffnes.com/" target="_blank">Dr. David Choffnes</a>, <strong>Advisor: </strong><a href="https://www.gamero-garrido.com/" target="_blank">Dr. Alexander Gamero Garrido</a></p>
                    <hr>
                </div>

            </article>

            <article>

                <header class="post-header">
                    <h1 class="post-title-research-page">
                        <span class="font-weight-bold"><span style="color: red;">Publications and Pre-Prints</span></span>
                    </h1>
                    <p class="desc"></p>
                </header>

                <div class="publications">

                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Under Review - EHJ-DH</abbr>
                                    <img src="../publications/images/heartdx-lm.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Automated Transformation of Unstructured Cardiovascular Diagnostic Reports into Structured Datasets Using Sequentially Deployed Large Language Models</div>
                                    <div class="author">
                                        <p><a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>, Lovedeep Dhingra, Arya Aminorroaya, Philip Adejumo, Girish N Nadkarni, Hua Xu, Cynthia Brandt, Evangelos K Oikonomou, Aline F Pedroso, Rohan Khera</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.medrxiv.org/content/medrxiv/early/2024/10/08/2024.10.08.24315035.full.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Background: Rich data in cardiovascular diagnostic testing are often sequestered in unstructured reports, limiting their use. <br/>

                                            Methods: We sequentially deployed generative and interpretative open-source large language models (LLMs; Llama2 70b, Llama2 13b). Using Llama2 70b, we generated varying formats of transthoracic echocardiogram (TTE) reports from 3000 real-world reports with paired structured elements. Using prompt-based supervised training, we fine-tuned Llama2 13b using sequentially larger batches of generated TTE reports as inputs, to extract data across 18 clinically-relevant echocardiographic fields. We evaluated the fine-tuned model, HeartDx-LM, on distinct datasets: (i) different time periods and formats at Yale New Haven Health System (YNHHS), (ii) Medical Information Mart for Intensive Care (MIMIC) III, and (iii) MIMIC IV. We used accuracy and Cohen's Kappa as evaluation metrics and have publicly released the HeartDX-LM model.<br/> 
                                            
                                            Results: HeartDX-LM was trained on 2,000 synthetic reports with varying formats and paired structured labels. We identified a lower threshold of 500 annotated reports required for fine-tuning to achieve consistent performance. At YNHHS, HeartDX-LM accurately extracted 69,144 of 70,032 values (98.7%) across 18 fields in the contemporary test set where paired structured data were available. In 100 older YNHHS reports, HeartDx-LM achieved 87.1% accuracy against expert annotations. In external validation sets from MIMIC-III and MIMIC-IV, HeartDx-LM correctly extracted 615 of 707 available values (87.9%) and 201 of 220 available values (91.3%), from 100 random, expert-annotated reports from each set. <br/>

                                            Conclusion: We developed and validated a novel approach using paired large and moderate-sized LLMs to transform free-text echocardiographic reports into tabular datasets.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Preprint</abbr>
                                    <img src="../publications/images/chadsvasc-1.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Retrieval-Augmented Generation for Extracting CHA₂DS₂-VASc Risk Factors from Unstructured Clinical Notes in Patients with Atrial Fibrillation</div>
                                    <div class="author">
                                        <p>Philip Adejumo, Phyllis Thangaraj, <a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>, Lovedeep Dhingra, Arya Aminorroaya, Rohan Khera</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://pubmed.ncbi.nlm.nih.gov/39371151/" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Background: Assessment of stroke risk in patients with atrial fibrillation (AF) is crucial for guiding anticoagulation therapy. CHA2DS2-VASc is a widely used score for defining this risk, but current assessments rely on manual calculation by clinicians or approximations from structured EHR data elements. Unstructured clinical notes contain rich information that could enhance risk assessment. We developed and validated a Retrieval-Augmented Generation (RAG) approach to extract CHA2DS2-VASc risk factors from unstructured notes in patients with AF.<br/>

                                            Methods: We employed a RAG architecture paired with the large language model, Llama3.1, to extract features relevant to CHA2DS2-VASc scores from unstructured notes. The model was deployed on a random set of 1,000 clinical notes (934 AF patients) from Yale New Haven Health System (YNHHS). To establish a gold standard, 2 clinicians manually reviewed and labeled CHA2DS2-VASc risk factors in a random subset of 200 notes. The CHA2DS2-VASc scores were calculated for each patient using structured data alone and by incorporating risk factors identified with RAG. We assessed performance across risk factors using macro-averaged area under the receiver operating characteristic (AUROC). For external validation, we utilized 100 manually labeled clinical notes from the MIMIC-IV database.<br/>

                                            Results: The RAG model demonstrated robust performance in extracting risk factors from clinical notes. In the 1000 clinical notes, RAG identified several risk factors more frequently than structured elements, including hypertension (82.4% vs 26.2%), stroke/TIA (62.9% vs 45.5%), vascular disease (83.4% vs 56.6%), and diabetes (84.1% vs 47.2%). In the 200 expert-annotated notes, the RAG approach achieved high performance for various risk factors, with AUROCs ranging from 0.96 to 0.98 for hypertension, diabetes, and age ≥75 years. Incorporating risk factors identified by RAG increased CHA2DS2-VASc scores compared with using structured data alone.<br/>

                                            Conclusion: An LLM-optimized RAG can accurately extract CHA2DS2-VASc risk factors from unstructured clinical notes in AF patients. This approach can enable computable risk assessment and guide appropriate anticoagulation therapy.<br/>
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Preprint</abbr>
                                    <img src="../publications/images/present-shd.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">An Ensemble Deep Learning Algorithm for Structural Heart Disease Screening Using Electrocardiographic Images: PRESENT SHD</div>
                                    <div class="author">
                                        <p>Lovedeep Singh Dhingra, Arya Aminorroaya, Veer Sangha, Aline Pedroso Camargos, <a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>, Andreas Coppi, Murilo Foppa, Luisa Campos Caldeira Brant, Sandhi M Barreto, Antônio LP Ribeiro, Harlan Krumholz, Evangelos K Oikonomou, Rohan Khera</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.medrxiv.org/content/10.1101/2024.10.06.24314939v1" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://www.cards-lab.org/present-shd" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Background: Identifying structural heart diseases (SHDs) early can change the course of the disease, but their diagnosis requires cardiac imaging, which is limited in accessibility.<br/>

                                            Objective: To leverage 12-lead ECG images for automated detection and prediction of multiple SHDs using a novel deep learning model.<br/>

                                            Methods: We developed a series of convolutional neural network models for detecting a range of individual SHDs from images of ECGs with SHDs defined by transthoracic echocardiograms (TTEs) performed within 30 days of the ECG at the Yale New Haven Hospital (YNHH). SHDs were defined based on TTEs with LV ejection fraction 40%, moderate-to-severe left-sided valvular disease (aortic/mitral stenosis or regurgitation), or severe left ventricular hypertrophy (IVSd > 1.5cm and diastolic dysfunction). We developed an ensemble XGBoost model, PRESENT-SHD, as a composite screen across all SHDs. We validated PRESENT-SHD at 4 US hospitals and a prospective population-based cohort study, the Brazilian Longitudinal Study of Adult Health (ELSA-Brasil), with concurrent protocolized ECGs and TTEs. We also used PRESENT-SHD for risk stratification of new-onset SHD or heart failure (HF) in clinical cohorts and the population-based UK Biobank (UKB).<br/>

                                            Results: The models were developed using 261,228 ECGs from 93,693 YNHH patients and evaluated on a single ECG from 11,023 individuals at YNHH (19% with SHD), 44,591 across external hospitals (20-27% with SHD), and 3,014 in the ELSA-Brasil (3% with SHD). In the held-out test set, PRESENT-SHD demonstrated an AUROC of 0.886 (0.877-894), sensitivity of 89%, and specificity of 66%. At hospital-based sites, PRESENT-SHD had AUROCs ranging from 0.854-0.900, with sensitivities and specificities of 93-96% and 51-56%, respectively. The model generalized well to ELSA-Brasil (AUROC, 0.853 [0.811-0.897], sensitivity 88%, specificity 62%). PRESENT-SHD performance was consistent across demographic subgroups. A positive PRESENT-SHD screen portended a 2- to 4-fold higher risk of new-onset SHD/HF, independent of demographics, comorbidities, and the competing risk of death across clinical sites and UKB, with high predictive discrimination.<br/>

                                            Conclusion: We developed and validated PRESENT-SHD, an AI-ECG tool identifying a range of SHD using images of 12-lead ECGs, representing a robust, scalable, and accessible modality for automated SHD screening and risk stratification.<br/>
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Under Review - JIMMI</abbr>
                                    <img src="../publications/images/enn2.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant Neural Networks for Controlling Dynamic Spatial Light Modulators</div>
                                    <div class="author">
                                        <p><a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>*, Rui Wang*, Darrel D'Souza, Jonathan P Singer, Robin Walters</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <!-- <a href="https://www.nature.com/articles/s44161-024-00469-1" class="btn btn-sm z-depth-0" role="button">PDF</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Spatial Light Modulators (SLMs) are devices that are capable of manipulating incident light by passing it through an
                                            array of phase/intensity altering pixels. A recent alternative design involves creating a phase mask by directing a thin
                                            film of fluid
                                            with thermocapillary forces generated by a controlled temperature map. However, it is difficult to
                                            determine the input temperature signal necessary to induce a given height profile. The relationship between
                                            temperature and height is given by the thin film
                                            equation, a fourth-order non-linear PDE, which is difficult to solve
                                            numerically. To address this problem, we train deep neural networks to directly solve the inverse problem, mapping
                                            from the desired height profiles to the needed temperature patterns. We
                                            design novel equivariant networks
                                            incorporating scale and rotation symmetry of the underlying thin film equation. We demonstrate the effectiveness of
                                            equivariant models for learning the complex relationship between input temperature signals and the resulti
                                            ng light
                                            patterns, showing they are more accurate than non
                                            -
                                            equivariant baselines and very computationally efficient. This work
                                            has implications for a range of applications, including high
                                            -
                                            power laser systems, and could lead to more efficient and
                                            effective
                                            ways to deploy the process of modulation of light in SLMs in a variety of applications.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Nature Cardiovascular Research</abbr>
                                    <img src="../publications/images/Lpa.webp" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Development and multinational validation of an algorithmic strategy for high Lp(a) screening</div>
                                    <div class="author">
                                        <p>Arya Aminorroaya, Lovedeep S Dhingra, Evangelos K Oikonomou, Seyedmohammad Saadatagah, Phyllis Thangaraj, <a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>, Erica S Spatz, Rohan Khera</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.nature.com/articles/s44161-024-00469-1" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://www.cards-lab.org/arise" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Elevated lipoprotein (a) (Lp(a)) is associated with premature atherosclerotic cardiovascular disease. However, fewer than 0.5% of individuals undergo Lp(a) testing, limiting the evaluation and use of novel targeted therapeutics currently under development. Here we describe the development of a machine learning model for targeted screening for elevated Lp(a) (≥150 nmol l−1) in the UK Biobank (N = 456,815), the largest cohort with protocolized Lp(a) testing. We externally validated the model in 3 large cohort studies, ARIC (N = 14,484), CARDIA (N = 4,124) and MESA (N = 4,672). The model, Algorithmic Risk Inspection for Screening Elevated Lp(a) (ARISE), reduced the number needed to test to find one individual with elevated Lp(a) by up to 67.3%, based on the probability threshold, with consistent performance across external validation cohorts. ARISE could be used to optimize screening for elevated Lp(a) using commonly available clinical features, with the potential for its deployment in electronic health records to enhance the yield of Lp(a) testing in real-world settings.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>
                    
                    <!-- haojie FourTran icrl 2024 -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Under Review - Nature Communications</abbr>
                                    <img src="../publications/images/rct-gan-1.jpg" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">A Novel Digital Twin Strategy to Examine the Implications of Randomized Control Trials for Real-World Populations</div>
                                    <div class="author">
                                        <p>Phyllis M Thangaraj*, <a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar*</a>, Sicong Huang, Girish Nadkarni, Bobak Mortazavi, Evangelos K Oikonomou, Rohan Khera</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10996766/" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://haojhuang.github.io/fourtran_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a> -->
                                        <!-- <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Randomized clinical trials (RCTs) are essential to guide medical practice; however, their generalizability to a given population is often uncertain. We developed a statistically informed Generative Adversarial Network (GAN) model, RCT-Twin-GAN, that leverages relationships between covariates and outcomes and generates a digital twin of an RCT (RCT-Twin) conditioned on covariate distributions from a second patient population. We used RCT-Twin-GAN to reproduce treatment effect outcomes of the Systolic Blood Pressure Intervention Trial (SPRINT) and the Action to Control Cardiovascular Risk in Diabetes (ACCORD) Blood Pressure Trial, which tested the same intervention but had different treatment effect results. To demonstrate treatment effect estimates of each RCT conditioned on the other RCT patient population, we evaluated the cardiovascular event-free survival of SPRINT digital twins conditioned on the ACCORD cohort and vice versa (SPRINT-conditioned ACCORD twins). The conditioned digital twins were balanced by the intervention arm (mean absolute standardized mean difference (MASMD) of covariates between treatment arms 0.019 (SD 0.018), and the conditioned covariates of the SPRINT-Twin on ACCORD were more similar to ACCORD than a sprint (MASMD 0.0082 SD 0.016 vs. 0.46 SD 0.20). Most importantly, across iterations, SPRINT conditioned ACCORD-Twin datasets reproduced the overall non-significant effect size seen in ACCORD (5-year cardiovascular outcome hazard ratio (95% confidence interval) of 0.88 (0.73–1.06) in ACCORD vs median 0.87 (0.68–1.13) in the SPRINT conditioned ACCORD-Twin), while the ACCORD conditioned SPRINT-Twins reproduced the significant effect size seen in SPRINT (0.75 (0.64–0.89) vs median 0.79 (0.72–0.86)) in ACCORD conditioned SPRINT-Twin). Finally, we describe the translation of this approach to real-world populations by conditioning the trials on an electronic health record population. Therefore, RCT-Twin-GAN simulates the direct translation of RCT-derived treatment effects across various patient populations with varying covariate distributions.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>


                    <!-- Haojie IJRR 2024 Leverage symmetries in pick and place  -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Preprint</abbr>
                                    <img src="../publications/images/id-shd.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Study Protocol for the Artificial Intelligence-Driven Evaluation of Structural Heart Diseases Using Wearable Electrocardiogram (ID-SHD)</div>
                                    <div class="author">
                                        <p>Arya Aminorroaya, Lovedeep Singh Dhingra, Aline Pedroso Camargos, <a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>, Akshay Khunte, Veer Sangha, Robert L McNamara, Norrisa Haynes, Evangelos K Oikonomou, Rohan Khera</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10984075/" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Portable devices capable of electrocardiogram (ECG) acquisition have the potential to enhance structural heart disease (SHD) management by enabling early detection through artificial intelligence-ECG (AI-ECG) algorithms. However, the performance of these AI algorithms for identifying SHD in a real-world screening setting is unknown. To address this gap, we aim to evaluate the validity of our wearable-adapted AI algorithm, which has been previously developed and validated for detecting SHD from single-lead portable ECGs in patients undergoing routine echocardiograms in the Yale New Haven Hospital (YNHH).
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>
                    

                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Under Review</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/ecg-gpt.jpg" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Automated Diagnostic Reports from Images of Electrocardiograms at the Point-of-Care</div>
                                    <div class="author">
                                        <p>Akshay Khunte, Veer Sangha, Evangelos K Oikonomou, Lovedeep S Dhingra, Arya Aminorroaya, Andreas Coppi, <a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>, Bobak J Mortazavi, Deepak L Bhatt, Harlan M Krumholz, Girish N Nadkarni, Akhil Vaid, Rohan Khera</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10889032/" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://www.cards-lab.org/ecg-gpt" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Timely and accurate assessment of electrocardiograms (ECGs) is crucial for diagnosing, triaging, and clinically managing patients. Current workflows rely on a computerized ECG interpretation using rule-based tools built into the ECG signal acquisition systems with limited accuracy and flexibility. In low-resource settings, specialists must review every single ECG for such decisions, as these computerized interpretations are not available. Additionally, high-quality interpretations are even more essential in such low-resource settings as there is a higher burden of accuracy for automated reads when access to experts is limited. Artificial Intelligence (AI)-based systems have the prospect of greater accuracy yet are frequently limited to a narrow range of conditions and do not replicate the full diagnostic range. Moreover, these models often require raw signal data, which are unavailable to physicians and necessitate costly technical integrations that are currently limited. To overcome these challenges, we developed and validated a format-independent vision encoder-decoder model – ECG-GPT – that can generate free-text, expert-level diagnosis statements directly from ECG images. The model shows robust performance, validated on 2.6 million ECGs across 6 geographically distinct health settings: (1) 2 large and diverse US health systems- Yale-New Haven and Mount Sinai Health Systems, (2) a consecutive ECG dataset from a central ECG repository from Minas Gerais, Brazil, (3) the prospective cohort study, UK Biobank, (4) a Germany-based, publicly available repository, PTB-XL, and (5) a community hospital in Missouri. The model demonstrated consistently high performance (AUROC≥0.81) across a wide range of rhythm and conduction disorders. This can be easily accessed via a web-based application capable of receiving ECG images and represents a scalable and accessible strategy for generating accurate, expert-level reports from images of ECGs, enabling accurate triage of patients globally, especially in low-resource settings.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Preprint</abbr>
                                    <img src="../publications/images/rct-gan-2.jpg" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">RCT-Twin-GAN Generates Digital Twins of Randomized Control Trials Adapted to Real-world Patients to Enhance their Inference and Application</div>
                                    <div class="author">
                                        <p>Phyllis M Thangaraj*, <a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar*</a>, Evangelos K Oikonomou, Rohan Khera</p>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10723568/" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Background:
                                            Randomized clinical trials (RCTs) are designed to produce evidence in selected populations. Assessing their effects in the real-world is essential to change medical practice, however, key populations are historically underrepresented in the RCTs. We define an approach to simulate RCT-based effects in real-world settings using RCT digital twins reflecting the covariate patterns in an electronic health record (EHR).
                                            
                                            Methods:
                                            We developed a Generative Adversarial Network (GAN) model, RCT-Twin-GAN, which generates a digital twin of an RCT (RCT-Twin) conditioned on covariate distributions from an EHR cohort. We improved upon a traditional tabular conditional GAN, CTGAN, with a loss function adapted for data distributions and by conditioning on multiple discrete and continuous covariates simultaneously. We assessed the similarity between a Heart Failure with preserved Ejection Fraction (HFpEF) RCT (TOPCAT), a Yale HFpEF EHR cohort, and RCT-Twin. We also evaluated cardiovascular event-free survival stratified by Spironolactone (treatment) use.
                                            
                                            Results:
                                            By applying RCT-Twin-GAN to 3445 TOPCAT participants and conditioning on 3445 Yale EHR HFpEF patients, we generated RCT-Twin datasets between 1141–3445 patients in size, depending on covariate conditioning and model parameters. RCT-Twin randomly allocated spironolactone (S)/ placebo (P) arms like an RCT, was similar to RCT by a multi-dimensional distance metric, and balanced covariates (median absolute standardized mean difference (MASMD) 0.017, IQR 0.0034–0.030). The 5 EHR-conditioned covariates in RCT-Twin were closer to the EHR compared with the RCT (MASMD 0.008 vs 0.63, IQR 0.005–0.018 vs 0.59–1.11). RCT-Twin reproduced the overall effect size seen in TOPCAT (5-year cardiovascular composite outcome odds ratio (95% confidence interval) of 0.89 (0.75–1.06) in RCT vs 0.85 (0.69–1.04) in RCT-Twin).
                                            
                                            Conclusions:
                                            RCT-Twin-GAN simulates RCT-derived effects in real-world patients by translating these effects to the covariate distributions of EHR patients. This key methodological advance may enable the direct translation of RCT-derived effects into real-world patient populations and may enable causal inference in real-world settings.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Preprint</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/cards-plus.jpg" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">CarDS-Plus ECG Platform: Development and Feasibility Evaluation of a Multiplatform Artificial Intelligence Toolkit for Portable and Wearable Device Electrocardiograms</div>
                                    <div class="author">
                                        <p><a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>, Evangelos K Oikonomou, Rohan Khera</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10593062/" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>In the rapidly evolving landscape of modern healthcare, the integration of wearable and portable technology provides a unique opportunity for personalized health monitoring in the community. Devices like the Apple Watch, FitBit, and AliveCor KardiaMobile have revolutionized the acquisition and processing of intricate health data streams that were previously accessible only through devices only available to healthcare providers. Amidst the variety of data collected by these gadgets, single-lead electrocardiogram (ECG) recordings have emerged as a crucial source of information for monitoring cardiovascular health. Notably, there has been significant advances in artificial intelligence capable of interpreting these 1-lead ECGs, facilitating clinical diagnosis as well as the detection of rare cardiac disorders. This design study describes the development of an innovative multi-platform system aimed at the rapid deployment of AI-based ECG solutions for clinical investigation and care delivery. The study examines various design considerations, aligning them with specific applications, and develops data flows to maximize efficiency for research and clinical use. This process encompasses the reception of single-lead ECGs from diverse wearable devices, channeling this data into a centralized data lake, and facilitating real-time inference through AI models for ECG interpretation. An evaluation of the platform demonstrates a mean duration from acquisition to reporting of results of 33.0 to 35.7 seconds, after a standard 30 second acquisition, allowing the complete process to be completed in 63.0 to 65.7 seconds. There were no substantial differences in acquisition to reporting across two commercially available devices (Apple Watch and KardiaMobile). These results demonstrate the succcessful translation of design principles into a fully integrated and efficient strategy for leveraging 1-lead ECGs across platforms and interpretation by AI-ECG algorithms. Such a platform is critical to translating AI discoveries for wearable and portable ECG devices to clinical impact through rapid deployment.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">Preprint</abbr>
                                    <img src="../publications/images/aortic-stenosis.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Deep Learning-enabled Detection of Aortic Stenosis from Noisy Single Lead Electrocardiograms</div>
                                    <div class="author">
                                        <p>Arya Aminorroaya, Lovedeep Singh Dhingra, Veer Sangha, Evangelos K Oikonomou, Akshay Khunte, <a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>, Aline Pedroso Camargos, Norrisa Haynes, Ira Hofer, David Ouyang, Girish Nadkarni, Rohan Khera</p>
                                    </div>

                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://www.medrxiv.org/content/10.1101/2023.09.29.23296310v1" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Background Due to the lack of a feasible screening strategy, aortic stenosis (AS) is often diagnosed after the development of clinical symptoms, representing advanced stages of disease. Portable and wearable devices capable of recording electrocardiograms (ECGs) can be used for scalable screening for AS, if the diagnosis can be made with a single-lead ECG, despite potentially noisy acquisition.

                                            Methods Using electronic health records and imaging data from a large, diverse hospital system (2015-2022), we developed a deep learning-based approach to detect moderate/severe AS using a single-lead ECG. We used ECGs paired with echocardiograms obtained within 30 days of each other to develop the model. We extracted lead I signal data from clinical ECG and augmented it with random Gaussian noise. We trained a convolutional neural network (CNN) to identify TTE-confirmed AS using noisy single-lead ECGs. Finally, we used the CNN model probabilities, along with patient age and sex, as predictive inputs to train an extreme gradient boosting (XGBoost) model to detect moderate/severe AS.
                                            
                                            Results The model was developed in 75,901 ECGs/35,992 patients (median age 61 [interquartile range (IQR) 47-72] years, 54.3% women, 9.5% Black) and validated in 3,733 patients (median age 61 [IQR 47-72] years, 53.4% women, 9.7% Black). In the held-out validation set, the ensemble XGBoost model achieved an AUROC of 0.829 (95% CI: 0.800-0.855), with a sensitivity of 90.4% and specificity of 58.7% for detecting moderate/severe AS. For detecting severe AS, the model’s AUROC was 0.846 (95% CI, 0.778-0.899), with a sensitivity of 94.3% and specificity of 57.0%. In the test set with a 4.5% prevalence of moderate/severe AS, the model had a PPV of 9.3% and an NPV of 99.2%. In simulated cohorts with 1% and 20% prevalence of moderate/severe AS, the model’s NPVs varied from 99.8% to 96.1%, and PPV from 2.2% to 35.4%, respectively.
                                            
                                            Conclusion We developed a novel portable– and wearable-adapted deep learning approach for the detection of moderate/severe AS from noisy single-lead ECGs. Our approach represents a highly sensitive, feasible, and scalable strategy for community-based AS screening.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICLR 2023</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/enn.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Controlling Dynamic Spatial Light Modulators using Equivariant Neural Networks</div>
                                    <div class="author">
                                        <p><a href="../index.html" target="_blank" rel="noopener noreferrer">Sumukh Vasisht Shankar</a>, Darrel D'Souza, Jonathan P. Singer, Robin Walters</p>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://openreview.net/pdf?id=pKrOHg9PXtc" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Spatial Light Modulators (SLMs) are devices that can modulate the amplitude or the phase of a beam of light. These devices are used in applications such as beam front aberration and microscopic manipulation with optical tweezers. Here, we study the problem of learning to modulate light in a new type of temperature-controlled SLM. These SLMs are panels that use a thin viscous film in which shallow wave patterns can be induced by varying the temperature of the panel. This method can be used for modulating light such as high-power lasers. The problem here is to learn which input temperature signal is necessary in order to induce a given pattern in the reflected light. We propose a deep equivariant model to learn this relationship. We generate a synthetic dataset consisting of temperature signals and corresponding light patterns by simulating the thin film lubrication equation that governs the phenomenon of thermocapillary dewetting. We use this dataset to train our networks. We demonstrate the advantage of using equivariant neural networks over convolutional neural networks in order to learn the mapping.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

            </article>

            </div>

        </div>


    <article>

        <div class="social">
            <div class="contact-icons">
                <a href="mailto:sumukh.vasishtshankar@yale.edu"><i class="fas fa-envelope"></i></a>
                <a href="https://scholar.google.com/citations?user=pFW1ZlIAAAAJ&hl=en" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
                <a href="https://github.com/sumukh-vasisht" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
                <a href="https://www.linkedin.com/in/sumukh-vasisht-s/" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
                <a href="https://twitter.com/VasishtSumukh" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            </div>
            <div class="contact-note">
                <!-- Any contact note here -->
            </div>
        </div>

    </article>

    </div>

    </div>

    <!-- Footer -->


    <footer class="sticky-bottom mt-5 ">
        <div class="container ">
            Made with <a href="http://jekyllrb.com/ " target="_blank " rel="noopener noreferrer ">Jekyll</a> and Bootstrap.
        </div>
    </footer>

</body>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="../assets/js/mansory.js" type="text/javascript"></script>

<!-- Enable Tooltips -->
<script type="text/javascript">
    $(function() {
        $('[data-toggle="tooltip"]').tooltip()
    })
</script>

<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="../assets/js/zoom.js"></script>

<!-- Load Common JS -->
<script src="../assets/js/common.js"></script>

<!-- MathJax -->
<script type="text/javascript">
    window.MathJax = {
        tex: {
            tags: 'ams'
        }
    };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-185703812-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-185703812-1');
</script>

<script>
    $(document).ready(function() {
        $('a.abstract').click(function() {
            $(this).parent().parent().find(".abstract.hidden").toggleClass('open');
        });
        $('a.bibtex').click(function() {
            $(this).parent().parent().find(".bibtex.hidden").toggleClass('open');
        });
        $('.navbar-nav').find('a').removeClass('waves-effect waves-light');
    });
</script>

</html>
